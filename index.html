<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>孙宏博 - Homepage</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 0;
        background: #f9f9f9;
        color: #333;
        line-height: 1.6;
      }
      nav {
        background: #800000;
        display: flex;
        justify-content: center;
        gap: 20px;
        padding: 10px 0;
        position: sticky;
        top: 0;
        z-index: 100;
      }
      nav a {
        color: white;
        text-decoration: none;
        font-weight: bold;
      }
      nav a:hover {
        text-decoration: underline;
      }
      .container {
        margin: 20px 150px 20px 100px;
        display: flex;
      }
      /* 左边固定头像栏 */
      .sidebar {
        width: 220px;
        flex-shrink: 0;
        position: sticky;
        top: 80px;
        align-self: flex-start;
        text-align: center;
        padding-right: 20px;
      }
      .sidebar img {
        width: 160px;
        border-radius: 10px;
        margin-bottom: 10px;
      }
      .subtitle {
        font-size: 14px;
        color: #666;
        margin-bottom: 10px;
      }
      .contact a {
        display: block;
        color: #800000;
        text-decoration: none;
        font-size: 14px;
        margin: 3px 0;
      }
      .contact a:hover {
        text-decoration: underline;
      }
      /* 右边主要内容 */
      .main {
        flex: 1;
      }
      .main section {
        margin-bottom: 40px;
      }
      h2 {
        border-bottom: 2px solid #ddd;
        padding-bottom: 5px;
        margin-top: 10px;
      }
      ul {
        padding-left: 20px;
      }
      footer {
        background: #800000;
        color: white;
        text-align: center;
        padding: 15px;
        margin-top: 40px;
      }
      .paper {
        display: flex;
        align-items: center;
        gap: 20px;
        margin-bottom: 30px;
        background: #fff;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
      }
      .paper img {
        width: 200px;
        border-radius: 5px;
      }
      .paper h3 {
        margin: 0;
        font-size: 18px;
        color: rgb(55, 84, 141);
        font-family: "Times New Roman", Times, serif;
      }
      .paper p {
        margin: 5px 0;
      }
      .work h3 {
        margin: 0 0 0 15px;
        font-size: 18px;
      }
      .work p {
        margin: 0 0 20px 15px;
      }
    </style>
  </head>
  <body>
    <nav>
      <a href="#about">About</a>
      <a href="#news">News</a>
      <a href="#publications">Publications</a>
      <!-- <a href="#related-work">Related Work</a> -->
      <a href="#education">Education</a>
      <a href="#honors">Honors</a>
      <a href="#activities">Activities</a>
    </nav>

    <div class="container">
      <!-- 左边头像栏 -->
      <aside class="sidebar">
        <img src="images/sunhongbo.png" alt="Profile Photo" />
        <div class="subtitle">
          研究方向：多模态大模型、多模态内容理解、细粒度视觉分析
        </div>
        <div class="contact">
        Researcher at TeleAI <br>（中国电信人工智能研究院）<br> 
        <a href="mailto:sunhongbo@pku.edu.cn">sunhongbo@pku.edu.cn</a>
        </div>
      </aside>

      <!-- 右边主要内容 -->
      <main class="main">
        <section id="about">
          <h2>👨‍💻 孙宏博</h2>
          <p>
            孙宏博，博士毕业于北京大学，入选2025年度北京“高创计划”青年人才托举工程，北京图象图形学学会BSIG
            2024优博，现任中电信人工智能科技有限公司视觉算法工程师。研究领域为多模态大模型、细粒度视觉分析，参与多模态基座大模型TeleMM和万物布控系统Telesearch2.0研发，TeleMM在国际权威评测MMMU、MME、国内权威评测OpenCompass（2024总榜单）上分别排名第一、第二、第三名。发表IEEE
            Trans.和CCF
            A类论文等10余篇，2次参加国际权威评测TRECVID视频语义搜索比赛，均获第一名。
          </p>
        </section>

        <section id="news">
          <h2>🔥 News</h2>
          <ul>

            <li>
              <b>2025.09</b> – 发布视频理解大模型强化学习开源项目<a
                  href="https://github.com/Hui-design/TSPO"
                  ><b>TSPO</b></a
                >，在VideMME、LVBench、MLVU等视频理解权威评测中均排名前五。
            </li>


            <li>
              <b>2025.07</b> – 入选2025年度北京“高创计划”青年人才托举工程。
            </li>

            <li>
              <b>2024.12</b> – 多模态大模型 TeleMM 在 OpenCompass 2024
              总榜单排名第三，超过GPT-4o，作为基础大模型广泛应用于电信的社会安防、城市治理、交通管治等实际业务。
            </li>

            <li>
              <b>2024.09</b> – 1篇论文被TIP 2024
              接收。
            </li>

            <li>
              <b>2024.08</b> – 博士学位论文获评“北京图象图形学学会 BSIG 2024
              优秀博士学位论文奖”。
            </li>

            <li>
              <b>2024.07</b> –
              加入中电信人工智能科技有限公司，担任视觉算法工程师，研发多模态基座大模型及其垂直细分领域应用。
            </li>

            <li>
              <b>2024.07</b> –
              北京大学计算机应用技术专业博士毕业，获得理学博士学位。
            </li>

            <li>
              <b>2024.04</b> –
              1篇论文被IJCAI 2024接收。
            </li>

          </ul>
        </section>

        <section id="publications">
          <h2>📝 代表性论文</h2>


          <div class="paper">
            <img src="images/simofe.png" alt="SIM-OFE" />
            <div>
              <h3>
                SIM-OFE: Structure Information Mining and Object-aware Feature
                Enhancement for Fine-Grained Visual Categorization
              </h3>
              <p>
                <b>Hongbo Sun</b>, Xiangteng He, Jinglin Xu and Yuxin Peng<br />
                <i
                  >IEEE Transactions on Image Processing (TIP), Vol. 33, pp.
                  5312–5326, 2024. (CCF A)</i
                >
                [<a
                  href="https://ieeexplore.ieee.org/abstract/document/10684043"
                  target="_blank"
                  ><b>Paper</b></a
                >]
              </p>
            </div>
          </div>


          <div class="paper">
            <img src="images/finefmpl.png" alt="FineFMPL" />
            <div>
              <h3>
                FineFMPL: Fine-grained Feature Mining Prompt Learning for
                Few-Shot Class Incremental Learning
              </h3>
              <p>
                <b>Hongbo Sun</b>, Jiahuan Zhou, Xiangteng He, Jinglin Xu and
                Yuxin Peng<br />
                <i
                  >Proceedings of the 33rd International Joint Conference on
                  Artificial Intelligence (IJCAI), Jeju, South Korea, Aug. 3-9,
                  2024. (CCF A)</i
                >[<a
                  href="https://www.ijcai.org/proceedings/2024/0144.pdf"
                  target="_blank"
                  ><b>Paper</b></a
                >]&nbsp;[<a
                  href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024"
                  target="_blank"
                  ><b>Code</b></a
                >]
              </p>
            </div>
          </div>


          <div class="paper">
            <img
              src="images/vlprompt.png"
              alt="Fine-Grained Visual Prompt Learning"
            />
            <div>
              <h3>
                Fine-Grained Visual Prompt Learning of Vision-Language Models
                for Image Recognition
              </h3>
              <p>
                <b>Hongbo Sun</b>, Xiangteng He, Jiahuan Zhou and Yuxin Peng<br />
                <i
                  >Proceedings of the 31st ACM International Conference on
                  Multimedia (ACM MM), Ottawa, Canada, Oct. 29-Nov. 3, 2023.
                  (CCF A)</i
                >
                [<a
                  href="https://zhoujiahuan1991.github.io/pub/MM2023_Finegrained.pdf"
                  target="_blank"
                  ><b>Paper</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img src="images/hcl.png" alt="HCL" />
            <div>
              <h3>
                HCL: Hierarchical Consistency Learning for Webly Supervised
                Fine-Grained Recognition
              </h3>
              <p>
                <b>Hongbo Sun</b>, Xiangteng He, Jinglin Xu and Yuxin Peng<br />
                <i
                  >IEEE Transactions on Multimedia (TMM), Vol. 26, pp.
                  5108–5119, 2024. (CCF B)</i
                >
                [<a
                  href="https://hexiangteng.github.io/papers/TMM%202023.pdf"
                  target="_blank"
                  ><b>Paper</b></a
                >]&nbsp;[<a
                  href="https://github.com/PKU-ICST-MIPL/HCL_TMM2023"
                  target="_blank"
                  ><b>Code</b></a
                >]&nbsp;[<a
                  href="https://mp.weixin.qq.com/s/-BGHEXejE_1DjovYW7XagQ"
                  target="_blank"
                  ><b>中文解读</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img src="images/simtrans.png" alt="SIM-Trans" />
            <div>
              <h3>
                SIM-Trans: Structure Information Modeling Transformer for
                Fine-grained Visual Categorization
              </h3>
              <p>
                <b>Hongbo Sun</b>, Xiangteng He and Yuxin Peng<br />
                <i
                  >Proceedings of the 30th ACM International Conference on
                  Multimedia (ACM MM), Lisbon, Portugal, Oct. 10-14, 2022. (CCF
                  A, Oral)</i
                >
                [<a href="https://arxiv.org/pdf/2208.14607" target="_blank"
                  ><b>Paper</b></a
                >][<a
                  href="https://github.com/PKU-ICST-MIPL/SIM-Trans_ACMMM2022"
                  target="_blank"
                  ><b>Code</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img
              src="images/dualmodal.png"
              alt="Dual-Modal Adaptive Online Prompting"
            />
            <div>
              <h3>
                Dual-Modal Adaptive Online Prompting and Knowledge Retention for
                Test-Time Adaptation
              </h3>
              <p>
                Zichen Liu, <b>Hongbo Sun</b>, Yuxin Peng and Jiahuan Zhou<br />
                <i
                  >Proceedings of the 38th AAAI Conference on Artificial
                  Intelligence (AAAI), Vancouver, Canada, Feb. 20-27, 2024. (CCF
                  A)</i
                >
                [<a
                  href="https://ojs.aaai.org/index.php/AAAI/article/view/29320"
                  target="_blank"
                  ><b>Paper</b></a
                >]
              </p>
            </div>
          </div>
<!-- 
          <div class="paper">
            <img src="images/videotext.png" alt="Video Text Detection" />
            <div>
              <h3>
                A Novel Approach for Video Text Detection and Recognition Based
                on a Corner Response Feature Map and Transferred Deep
                Convolutional Neural Network
              </h3>
              <p>
                Wei Lu, <b>Hongbo Sun</b>, Jinghui Chu, Xiangdong Huang, Jiexiao
                Yu<br />
                <i>IEEE Access, Vol. 6, pp. 40198–40211, 2018. (SCI, EI)</i> [<a
                  href="https://ieeexplore.ieee.org/abstract/document/8401484"
                  target="_blank"
                  ><b>Paper</b></a
                >]
              </p>
            </div>
          </div> -->
<!-- 
          <div class="paper">
            <div>
              <h3>基于FCM的复杂背景下人工文本提取方法</h3>
              <p>
                吕卫，<b>孙宏博</b>，褚晶辉<br />
                <i>中国发明专利，专利号：ZL201810017727.9</i> [<a
                  href="https://patents.google.com/patent/CN108154188B/zh"
                  target="_blank"
                  ><b>Patent</b></a
                >]
              </p>
            </div>
          </div> -->
        
        
        </section>
<!-- 
        <section id="related-work">
          <h2>📓 Related Work</h2>
          <div class="work">
            <h3>多模态基座大模型 TeleMM 研发 (2024.07–2024.12)</h3>
            <p>
              构建对复杂场景准确感知和决策的多模态大模型，支持视觉问答、阅读理解、逻辑推理等任务。提出文本引导的对象感知模块与多视野辨识性特征融合模块，提升模型精细感知与细粒度理解能力。TeleMM
              在 OpenCompass 2024 总榜单排名第3，超越
              GPT-4o，应用于电信安防、城市治理、交通管治等业务。
            </p>
          </div>

          <div class="work">
            <h3>
              基于细粒度跨模态提示学习的小样本类别增量学习 (2023.06–2024.01)
            </h3>
            <p>
              针对现实场景中类别持续增长的问题，提出细粒度跨模态提示学习方法，迁移预训练大模型知识并挖掘类别辨识性信息，在视觉与文本端对齐原型特征。在
              CUB-200-2011 上平均准确率提升 8.7%，成果发表于 IJCAI 2024 (CCF
              A)。
            </p>
          </div>

          <div class="work">
            <h3>
              基于细粒度视觉提示学习的视觉-语言预训练模型微调新范式
              (2022.12–2023.05)
            </h3>
            <p>
              实现小样本下游图像分类任务的高性能适配。提出细粒度视觉提示嵌入与双路自适应匹配机制，增强对象内信息交互与跨模态匹配能力。在11个数据集上平均性能提升超4%，在飞机数据集上提升超16%，成果发表于
              ACM MM 2023 (CCF A)。
            </p>
          </div>

          <div class="work">
            <h3>
              基于层级语义一致性学习的含噪细粒度图像分类 (2022.04–2022.11)
            </h3>
            <p>
              针对真实场景中标注噪声问题，提出利用图像-对象-部件层级的语义预测一致性检测开集与闭集噪声，并结合多层级对比学习增强模型表征能力。在3个含噪数据集上平均准确率达90.1%，成果发表于
              IEEE TMM 2024 (CCF B)。
            </p>
          </div>

          <div class="work">
            <h3>
              基于结构信息建模 Transformer 的细粒度图像分类 (2020.09–2022.03)
            </h3>
            <p>
              通过建模视觉对象内部结构信息与空间关系，增强模型对辨识性区域的理解。结合多层级特征融合与对比学习提升鲁棒性。在
              CUB-200-2011 上准确率达91.8%，成果发表于 ACM MM 2022 (Oral)
              并扩展发表于 TIP 2024 (CCF A)。
            </p>
          </div>

          <div class="work">
            <h3>视频中人工文本的自动检测识别系统 (2018.01–2019.07)</h3>
            <p>
              实现视频字幕等人工文本的自动检测与识别。提出角点响应特征图定位文本区域，结合投影分割与CNN判别真假文本行，使用FCM聚类提取干净文本层，最后通过OCR识别。成果发表于
              SCI 期刊并获发明专利授权。
            </p>
          </div>

          <div class="work">
            <h3>智能车胎防盗系统 (2016.05–2017.12)</h3>
            <p>
              设计基于单片机的车胎状态监控系统，集成超声波与角度传感器检测底盘异常，异常时触发短信报警与摄像头录像上传至APP。项目获京东方创新挑战赛全国三等奖，并获BOE创客实验室Special
              Offer。
            </p>
          </div>
        </section> -->

        <section id="education">
          <h2>📖 教育经历</h2>
          <ul>
            <li>2019.09-2024.07 北京大学 计算机应用技术 博士学位</li>
            <li>2016.09-2019.01 天津大学 信息与通信工程 硕士学位</li>
            <li>2012.09-2016.07 天津大学 电子信息工程 学士学位</li>
          </ul>
        </section>

        <section id="honors">
          <h2>🎖 奖励与荣誉</h2>
          <ul>
            <li>入选2025年度北京“高创计划”青年人才托举工程</li>
            <li>北京图象图形学学会BSIG 2024优秀博士学位论文奖</li>
            <li>
              2019,
              2020年国际视频分析权威评测TRECVID视频样例搜索比赛，均获第一名
            </li>
            <li>
              京东方（BOE）创新挑战赛全国总决赛三等奖，京东方（BOE）创客实验室Special
              Offer
            </li>
          </ul>
        </section>

        <section id="activities">
          <h2>📝 学术服务</h2>
          <ul>
            <li>AAAI程序委员会委员</li>
            <li>国际顶级会议和期刊（CVPR、ICCV、AAAI、IEEE TMM等）审稿人</li>
          </ul>
        </section>
      </main>
    </div>

    <footer>© 2025 电信人工智能研究院 孙宏博</footer>
  </body>
</html>
