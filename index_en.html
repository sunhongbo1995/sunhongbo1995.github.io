<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Hongbo Sun (Â≠ôÂÆèÂçö) - Homepage</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 0;
        background: #f9f9f9;
        color: #333;
        line-height: 1.6;
      }

      nav {
        background: #800000;
        display: flex;
        justify-content: center;
        gap: 20px;
        padding: 10px 0;
        position: sticky;
        top: 0;
        z-index: 100;
      }

      nav a {
        color: white;
        text-decoration: none;
        font-weight: bold;
      }

      nav a:hover {
        text-decoration: underline;
      }

      .container {
        margin: 20px 150px 20px 100px;
        display: flex;
      }

      /* Â∑¶ËæπÂõ∫ÂÆöÂ§¥ÂÉèÊ†è */
      .sidebar {
        width: 220px;
        flex-shrink: 0;
        position: sticky;
        top: 80px;
        align-self: flex-start;
        text-align: center;
        padding-right: 20px;
      }

      .sidebar img {
        width: 160px;
        border-radius: 10px;
        margin-bottom: 10px;
      }

      .subtitle {
        font-size: 14px;
        color: #666;
        margin-bottom: 10px;
      }

      .contact a {
        display: block;
        color: #800000;
        text-decoration: none;
        font-size: 14px;
        margin: 3px 0;
      }

      .contact a:hover {
        text-decoration: underline;
      }

      /* Âè≥Ëæπ‰∏ªË¶ÅÂÜÖÂÆπ */
      .main {
        flex: 1;
      }

      .main section {
        margin-bottom: 40px;
      }

      h2 {
        border-bottom: 2px solid #ddd;
        padding-bottom: 5px;
        margin-top: 10px;
      }

      ul {
        padding-left: 20px;
      }

      footer {
        background: #800000;
        color: white;
        text-align: center;
        padding: 15px;
        margin-top: 40px;
      }

      .paper {
        display: flex;
        align-items: center;
        gap: 20px;
        margin-bottom: 30px;
        background: #fff;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
      }

      .paper img {
        width: 200px;
        height: 125px;
        object-fit: fill;
        border-radius: 5px;
      }

      .paper h3 {
        margin: 0;
        font-size: 18px;
        color: rgb(55, 84, 141);
        font-family: "Times New Roman", Times, serif;
      }

      .paper p {
        margin: 5px 0;
      }

      .work h3 {
        margin: 0 0 0 15px;
        font-size: 18px;
      }

      .work p {
        margin: 0 0 20px 15px;
      }

      #news a {
        text-decoration: none;
        /* ÈªòËÆ§Êó†‰∏ãÂàíÁ∫ø */
      }

      #news a:hover {
        text-decoration: underline;
      }
    </style>

    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <nav>
      <a href="#about">About</a>
      <a href="#news">News</a>
      <a href="#publications">Publications</a>
      <!-- <a href="#related-work">Related Work</a> -->
      <a href="#education">Education</a>
      <a href="#honors">Honors</a>
      <a href="#activities">Activities</a>
    </nav>

    <div class="container">
      <!-- Â∑¶ËæπÂ§¥ÂÉèÊ†è -->
      <aside class="sidebar">
        <img src="images/sunhongbo.png" alt="Profile Photo" />
        <div class="subtitle">
          Research Interests: Multimodal Large Language Model (MLLM), Multimodal Content
          Understanding, Fine-Grained Visual Analysis
        </div>
        <div class="contact">
          Researcher at TeleAI <br />(Institute of Artificial Intelligence (TeleAI), China Telecom)<br />

          <a href="https://orcid.org/0000-0002-2639-9035">ORCID</a>
          <a
            href="https://scholar.google.com.hk/citations?user=w48SDn8AAAAJ&hl=zh-CN&oi=ao"
            >Google Scholar</a
          >
          <a href="mailto:sunhongbo@pku.edu.cn">sunhongbo@pku.edu.cn</a>
        </div>
      </aside>

      <!-- Âè≥Ëæπ‰∏ªË¶ÅÂÜÖÂÆπ -->
      <main class="main">
        <section id="about">
          <h2>üë®‚Äçüíª Hongbo Sun (Â≠ôÂÆèÂçö) <a href="https://sunhongbo1995.github.io/">[‰∏≠ÊñáÁâà]</a></h2>
          <p style="text-align: justify; text-justify: inter-ideograph">
       I am currently an AGI researcher at the Institute of Artificial Intelligence (TeleAI), China Telecom, where I focus on developing Multimodal Large Language Models (MLLMs) and advancing their applications in downstream domains. As a core contributor, I participated in the development of China Telecom‚Äôs multimodal large language model TeleMM and the TeleSearch 2.0 system designed for ubiquitous surveillance. TeleMM ranked first,
            second, and third respectively on the international authoritative
            benchmarks MMMU, MME, and the domestic authoritative benchmark 
            <a
              href="https://rank.opencompass.org.cn/leaderboard-multimodal/?m=24-12"
              style="text-decoration: none"
              ><b style="color: rgb(51, 122, 183)"
                >OpenCompass (2024 overall
                leaderboard)</b
              ></a
            >. 

          </p>
          <p style="text-align: justify; text-justify: inter-ideograph">
            
            I obtained my Ph.D. degree in Computer Applied Technology at Peking
            University (PKU) in 2024, attaining the Excellent Doctoral Dissertation
            Award of Beijing Society of Image and Graphics (BSIG).  I was selected into Young Elite Scientists Sponsorship Program of the Beijing High Innovation Plan in 2025. My research interests include MLLM, multimodal content understanding, and fine-grained visual analysis.
            
          </p>

          
        </section>

        <section id="news">
          <h2>üî• News</h2>
          <ul>
            <li><b>2025.11</b> ‚Äì 1 paper accepted by AAAI 2026.</li>

            <li>
              <b>2025.10</b> ‚Äì Ranked 3rd in the ICCV 2025 Multimodal Large Language
              Model Visual Reasoning Localization Challenge<a
                href="https://arxiv.org/pdf/2509.14142"
                ><b style="color: rgb(51, 122, 183)"
                  >&nbsp;MARS2: VG-RS&nbsp;</b
                ></a
              >.
            </li>

            <li>
              <b>2025.09</b> ‚Äì Released the open-source reinforcement learning project for video
              understanding large model <a
                href="https://github.com/Hui-design/TSPO"
                ><b style="color: rgb(51, 122, 183)">&nbsp;TSPO&nbsp;</b></a
              >, ranking top five in VideoMME, LVBench, and MLVU.
            </li>

            <li>
              <b>2025.07</b> ‚Äì Selected into Young Elite Scientists Sponsorship Program of the Beijing High Innovation Plan, 2025.
            </li>

            <li>
              <b>2024.12</b> ‚Äì Developed TeleMM as the core contributor, which ranked 3rd on
              the OpenCompass 2024 overall leaderboard, surpassing GPT-4o available at that time. It has been widely applied as the foundational model in China Telecom's businesses such as social security, urban governance,
              and traffic management.
            </li>

            <li><b>2024.09</b> ‚Äì 1 paper accepted by TIP.</li>

            <li>
              <b>2024.08</b> ‚Äì Excellent Doctoral Dissertation Award of Beijing Society of Image and Graphics (BSIG), 2024
            </li>

            <li>
              <b>2024.07</b> ‚Äì Joined Institute of Artificial Intelligence (TeleAI), China Telecom, as a AGI researcher, responsible for developing Multimodal Large Language Models and advancing their applications in downstream domains.
            </li>

            <li>
              <b>2024.07</b> ‚Äì Attained a Ph.D. degree in Computer Application Technology at Peking University (PKU).
            </li>
          </ul>
        </section>

        <section id="publications">
          <h2>üìù Selected Publications</h2>
          <div class="paper">
            <img src="images/tspo.png" alt="TSPO" />
            <div>
              <h3>
                TSPO: Temporal Sampling Policy Optimization for Long-form Video
                Language Understanding
              </h3>

              <p>
              Canhui Tang, Zifan Han, <b>Hongbo Sun</b>, Sanping Zhou, Xuchong Zhang,
              Xin Wei, Ye Yuan, Huayu Zhang, Jinglin Xu and Hao Sun<br />
              <i>AAAI Conference on Artificial Intelligence (AAAI), 2026. (CCF A) (Accepted)</i>
              [<a href="https://arxiv.org/pdf/2508.04369" target="_blank"><b>Paper</b></a>]&nbsp;[<a
                href="https://github.com/Hui-design/TSPO?tab=readme-ov-file" target="_blank"><b>Code</b></a>]&nbsp;[<a
                  href="https://mp.weixin.qq.com/s/2k-P4_A26UtG-uXbH6tkMw"
                  target="_blank"
                  ><b>Reported by TeleAI</b></a
                >]
            
               </p>

            </div>
          </div>

          <div class="paper">
            <img src="images/simofe.png" alt="SIM-OFE" />
            <div>
              <h3>
                SIM-OFE: Structure Information Mining and Object-aware Feature
                Enhancement for Fine-Grained Visual Categorization
              </h3>
              <p>
                <b>Hongbo Sun</b>, Xiangteng He, Jinglin Xu and Yuxin Peng<br />
                <i
                  >IEEE Transactions on Image Processing (TIP), Vol. 33, pp.
                  5312‚Äì5326, 2024. (CCF A)</i
                >
                [<a
                  href="https://ieeexplore.ieee.org/abstract/document/10684043"
                  target="_blank"
                  ><b>Paper</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img src="images/finefmpl.png" alt="FineFMPL" />
            <div>
              <h3>
                FineFMPL: Fine-grained Feature Mining Prompt Learning for
                Few-Shot Class Incremental Learning
              </h3>
              <p>
                <b>Hongbo Sun</b>, Jiahuan Zhou, Xiangteng He, Jinglin Xu and
                Yuxin Peng<br />
                <i
                  >Proceedings of the 33rd International Joint Conference on
                  Artificial Intelligence (IJCAI), Jeju, South Korea, Aug. 3-9,
                  2024. (CCF A)</i
                >[<a
                  href="https://www.ijcai.org/proceedings/2024/0144.pdf"
                  target="_blank"
                  ><b>Paper</b></a
                >]&nbsp;[<a
                  href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024"
                  target="_blank"
                  ><b>Code</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img
              src="images/dualmodal.png"
              alt="Dual-Modal Adaptive Online Prompting"
            />
            <div>
              <h3>
                Dual-Modal Adaptive Online Prompting and Knowledge Retention for
                Test-Time Adaptation
              </h3>
              <p>
                Zichen Liu, <b>Hongbo Sun</b>, Yuxin Peng and Jiahuan Zhou<br />
                <i
                  >Proceedings of the 38th AAAI Conference on Artificial
                  Intelligence (AAAI), Vancouver, Canada, Feb. 20-27, 2024. (CCF
                  A)</i
                >
                [<a
                  href="https://ojs.aaai.org/index.php/AAAI/article/view/29320"
                  target="_blank"
                  ><b>Paper</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img src="images/hcl.png" alt="HCL" />
            <div>
              <h3>
                HCL: Hierarchical Consistency Learning for Webly Supervised
                Fine-Grained Recognition
              </h3>
              <p>
                <b>Hongbo Sun</b>, Xiangteng He, Jinglin Xu and Yuxin Peng<br />
                <i
                  >IEEE Transactions on Multimedia (TMM), Vol. 26, pp.
                  5108‚Äì5119, 2024.</i
                >
                [<a
                  href="https://hexiangteng.github.io/papers/TMM%202023.pdf"
                  target="_blank"
                  ><b>Paper</b></a
                >]&nbsp;[<a
                  href="https://github.com/PKU-ICST-MIPL/HCL_TMM2023"
                  target="_blank"
                  ><b>Code</b></a
                >]&nbsp;[<a
                  href="https://mp.weixin.qq.com/s/-BGHEXejE_1DjovYW7XagQ"
                  target="_blank"
                  ><b>Reported by CCF-MM</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img
              src="images/vlprompt.png"
              alt="Fine-Grained Visual Prompt Learning"
            />
            <div>
              <h3>
                Fine-Grained Visual Prompt Learning of Vision-Language Models
                for Image Recognition
              </h3>
              <p>
                <b>Hongbo Sun</b>, Xiangteng He, Jiahuan Zhou and Yuxin Peng<br />
                <i
                  >Proceedings of the 31st ACM International Conference on
                  Multimedia (ACM MM), Ottawa, Canada, Oct. 29-Nov. 3, 2023.
                  (CCF A)</i
                >
                [<a
                  href="https://zhoujiahuan1991.github.io/pub/MM2023_Finegrained.pdf"
                  target="_blank"
                  ><b>Paper</b></a
                >]
              </p>
            </div>
          </div>

          <div class="paper">
            <img src="images/simtrans.png" alt="SIM-Trans" />
            <div>
              <h3>
                SIM-Trans: Structure Information Modeling Transformer for
                Fine-grained Visual Categorization
              </h3>
              
              <p>
              <b>Hongbo Sun</b>, Xiangteng He and Yuxin Peng<br />
              <i>Proceedings of the 30th ACM International Conference on
                Multimedia (ACM MM), Lisbon, Portugal, Oct. 10-14, 2022. (CCF
                A)(<font color="red"><strong>Oral, 5.9%</strong></font>)</i>
              [<a href="https://arxiv.org/pdf/2208.14607" target="_blank"><b>Paper</b></a>][<a
                href="https://github.com/PKU-ICST-MIPL/SIM-Trans_ACMMM2022" target="_blank"><b>Code</b></a>]
            </p>

            </div>
          </div>
        </section>

        <section id="education">
          <h2>üìñ Education</h2>
          <ul>
            <li>
              2019.09-2024.07 &emsp;Peking University &emsp; Computer Applied
              Technology &emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;Ph.D.
            </li>
            <li>
              2016.09-2019.01 &emsp;Tianjin University &emsp; Information and
              Communication Engineering &emsp;Master
            </li>
            <li>
              2012.09-2016.07 &emsp;Tianjin University &emsp; Electronic
              Information Engineering &emsp;
              &emsp;&emsp;&emsp;&emsp;&nbsp;Bachelor
            </li>
          </ul>
        </section>

        <section id="honors">
          <h2>üéñ Honors and Awards</h2>
          <ul>
            <li>
                          
              Selected into Young Elite Scientists Sponsorship Program of the Beijing High Innovation Plan, 2025

            </li>
            <li>
              Excellent Doctoral Dissertation Award of Beijing Society of Image and Graphics (BSIG), 2024
            </li>
            <li>
              First place in the TRECVID Video Instance Search Competition in 2019 and
              2020
            </li>
            <li>
              Third Prize in the National Finals of BOE Innovation Challenge, Achieved Special Offer from BOE Innovation Lab, 2016
            </li>
          </ul>
        </section>

        <section id="activities">
          <h2>üìù Academic Services</h2>
          <ul>
            <li>AAAI Program Committee Member</li>
            <li>
              Reviewer for top international conferences and journals (CVPR,
              ICCV, AAAI, IEEE TMM, etc.)
            </li>
          </ul>
        </section>
      </main>
    </div>

    <footer>
      ¬© 2025 Hongbo Sun, Institute of Artificial Intelligence (TeleAI), China Telecom. All rights reserved.
    </footer>
  </body>
</html>
